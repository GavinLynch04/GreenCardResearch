{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a2d85c8b",
      "metadata": {
        "id": "a2d85c8b"
      },
      "source": [
        "# **Prediction Modeling using AdaBoost**\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1SZxMXRZsESpFRyKDkg_QhZSjOekiM2_a\" width=\"700\" style=\"float: center\"/>\n",
        "\n",
        "- Ensemble method that combines several *weak learners* into a *strong learner*\n",
        "- Weak learners are trained *sequentially*\n",
        "- Each learner tries to correct the *weaknesses of its predecessor*\n",
        "\n",
        "### **AdaBoost**\n",
        "- Uses *stumps* as weak learners to form ensemble\n",
        "- Each stump is made by considering *previous stump's mistake*\n",
        "- Stumps have *different weightages* in final prediction\n",
        "\n",
        "  **Stump Weightage** $=\\eta \\ln\\big(\\frac{1-\\text{Total Error}}{\\text{Total Error}}\\big)$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08e3da84",
      "metadata": {
        "id": "08e3da84"
      },
      "source": [
        "### Case Study: Predicting the Acceptance of Personal Loan\n",
        "\n",
        "Data to be used: *Bank.csv*\n",
        "\n",
        "Following is the description of columns in *Bank.csv* file\n",
        "\n",
        "<TABLE CAPTION=\"Personal Loan Dataset\">\n",
        "<TR><TD><B>Variable</B></TD><TD><B>Description</B></TD></TR>\n",
        "<TR><TD>Age</TD><TD>Customer's age</TD></TR>\n",
        "<TR><TD>Experience</TD><TD># years of professional experience</TD></TR>\n",
        "<TR><TD>Income</TD><TD>Annual income of the customer (&#36;000)</TD></TR>\n",
        "<TR><TD>Family</TD><TD>Family size of the customer</TD></TR>\n",
        "<TR><TD>CCAvg</TD><TD>Avg. spending on credit cards per month (&#36;000)</TD></TR>\n",
        "<TR><TD>Education</TD><TD>Education Level. 1: Undergrad; 2: Graduate; 3: Advanced/Professional</TD></TR>   \n",
        "<TR><TD>Mortgage</TD><TD>Value of house mortgage if any. (&#36;000)</TD></TR>\n",
        "<TR><TD>Securities Account</TD><TD>Does the customer have a securities account with the bank?</TD></TR>\n",
        "<TR><TD>CD Account</TD><TD>Does the customer have a certificate of deposit (CD) account with the bank?</TD></TR>\n",
        "<TR><TD>Online</TD><TD>Does the customer use internet banking facilities?</TD></TR>\n",
        "<TR><TD>CreditCard</TD><TD>Does the customer use a credit card issued by the bank?</TD></TR>\n",
        "<TR><TD>Personal Loan (outcome)</TD><TD>Did this customer accept the personal loan offered in the campaign?</TD></TR>\n",
        "</TABLE>\n",
        "\n",
        "In `Personal Loan` Column:\n",
        "\n",
        "- 0: Did not accept loan\n",
        "- 1: Accepted loan"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bd693da",
      "metadata": {
        "id": "4bd693da"
      },
      "source": [
        "### Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ab9604e",
      "metadata": {
        "id": "4ab9604e"
      },
      "outputs": [],
      "source": [
        "import pandas as pd                  # Pandas\n",
        "import numpy as np                   # Numpy\n",
        "from matplotlib import pyplot as plt # Matplotlib\n",
        "\n",
        "# Package to implement AdaBoost\n",
        "import sklearn\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "# Package to implement Grid Search Cross Validation\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# Package for generating confusion matrix\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# Package for generating classification report\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Package to record time\n",
        "import time\n",
        "\n",
        "# Package for Data pretty printer\n",
        "from pprint import pprint\n",
        "\n",
        "# Ignore Deprecation Warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ed9b74c",
      "metadata": {
        "id": "4ed9b74c"
      },
      "source": [
        "### Import Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0cd6c0be",
      "metadata": {
        "id": "0cd6c0be"
      },
      "outputs": [],
      "source": [
        "# Import Data\n",
        "bank_df = pd.read_csv('Bank.csv')\n",
        "bank_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbd9fad0",
      "metadata": {
        "id": "bbd9fad0"
      },
      "outputs": [],
      "source": [
        "bank_df['Personal Loan'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "398040d9",
      "metadata": {
        "id": "398040d9"
      },
      "source": [
        "Almost 90% of the instances belong to class 0 (customers who rejected loan).\n",
        "\n",
        "Therefore, it is a highly *imbalanced* dataset."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Statistical Description\n",
        "bank_df.describe().T"
      ],
      "metadata": {
        "id": "zbK9WCh_wLMf"
      },
      "id": "zbK9WCh_wLMf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "42072cec",
      "metadata": {
        "id": "42072cec"
      },
      "source": [
        "### Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52d1738a",
      "metadata": {
        "id": "52d1738a"
      },
      "outputs": [],
      "source": [
        "# Selecting data correponding to Input Features X and Outcome y\n",
        "X = bank_df.drop(columns=['Personal Loan'])\n",
        "y = bank_df['Personal Loan']\n",
        "\n",
        "\n",
        "# Data Partitioning into train and test sets\n",
        "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.3, random_state=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "870be840",
      "metadata": {
        "id": "870be840"
      },
      "source": [
        "## **Implementing AdaBoost for Classification**\n",
        "\n",
        "### ***Hyperparameters of AdaBoost***\n",
        "\n",
        "### `n_estimators`:\n",
        "- The maximum number of weak learners at which boosting is terminated\n",
        "- In case of perfect fit, the learning procedure is stopped early\n",
        "- Default = 50\n",
        "- Input options → integer\n",
        "\n",
        "### `learning_rate` ($\\eta$):\n",
        "- Weight applied to each classifier at each boosting iteration\n",
        "- A higher learning rate increases the contribution of each weak learner\n",
        "- Default = 1.0\n",
        "- Input options → float"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04057072",
      "metadata": {
        "id": "04057072"
      },
      "source": [
        "### **Hyperparameter Tuning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7398b5bf",
      "metadata": {
        "id": "7398b5bf"
      },
      "outputs": [],
      "source": [
        "# Define your model\n",
        "classifier = AdaBoostClassifier(algorithm = 'SAMME', random_state = 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "564add4d",
      "metadata": {
        "id": "564add4d"
      },
      "outputs": [],
      "source": [
        "# Start with an initial guess for parameters\n",
        "n_estimators = [int(x) for x in np.linspace(start = 5, stop = 500, num = 10)]\n",
        "\n",
        "learning_rate = [x for x in np.arange(0.1, 2.1, 0.1)]\n",
        "\n",
        "# Create the random grid\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'learning_rate': learning_rate\n",
        "}\n",
        "\n",
        "pprint(random_grid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "984f7d94",
      "metadata": {
        "id": "984f7d94"
      },
      "outputs": [],
      "source": [
        "# Creating stratified folds\n",
        "folds = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76f81b6e",
      "metadata": {
        "id": "76f81b6e"
      },
      "outputs": [],
      "source": [
        "# Call RandomizedSearchCV()\n",
        "random_cv = RandomizedSearchCV(estimator = classifier,\n",
        "                              param_distributions = random_grid,\n",
        "                              n_iter = 100,\n",
        "                              scoring = 'f1_macro',\n",
        "                              cv = folds,\n",
        "                              verbose = 2,\n",
        "                              random_state = 42,\n",
        "                              n_jobs = -1) # Will utilize all available CPUs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea47a5e0",
      "metadata": {
        "id": "ea47a5e0"
      },
      "outputs": [],
      "source": [
        "# Fit the model\n",
        "start = time.time()            # Start Time\n",
        "random_cv.fit(train_X, train_y)\n",
        "stop = time.time()             # End Time\n",
        "print(f\"Training time: {stop - start}s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7510144",
      "metadata": {
        "id": "e7510144"
      },
      "outputs": [],
      "source": [
        "print('Initial score: ', random_cv.best_score_)\n",
        "print('Initial parameters: ', random_cv.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36107e48",
      "metadata": {
        "id": "36107e48"
      },
      "outputs": [],
      "source": [
        "# Create the parameter grid based on the results of random search\n",
        "param_grid = {'n_estimators': [400, 420, 440, 460, 480, 500],\n",
        "              'learning_rate': [1.15, 1.20, 1.25]\n",
        "}\n",
        "\n",
        "pprint(param_grid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bba92b3b",
      "metadata": {
        "id": "bba92b3b"
      },
      "outputs": [],
      "source": [
        "# Call GridSearchCV()\n",
        "grid_cv = GridSearchCV(estimator = classifier,\n",
        "                        param_grid = param_grid,\n",
        "                        scoring= 'f1_macro',\n",
        "                        cv = folds,\n",
        "                        verbose = 1,\n",
        "                        n_jobs = -1) # Will utilize all available CPUs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3be9611c",
      "metadata": {
        "id": "3be9611c"
      },
      "outputs": [],
      "source": [
        "# Fit the model\n",
        "start = time.time()            # Start Time\n",
        "grid_cv.fit(train_X, train_y)\n",
        "stop = time.time()             # End Time\n",
        "print(f\"Training time: {stop - start}s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76f5982a",
      "metadata": {
        "id": "76f5982a"
      },
      "outputs": [],
      "source": [
        "print('Improved score: ', grid_cv.best_score_)\n",
        "print('Improved parameters: ', grid_cv.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe21bd60",
      "metadata": {
        "id": "fe21bd60"
      },
      "source": [
        "### **Analyzing the performance of each stump in the ensemble**\n",
        "\n",
        "**Total Error of each stump**: Sum of weights associated with incorrectly classified instances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7ef6eea",
      "metadata": {
        "id": "a7ef6eea"
      },
      "outputs": [],
      "source": [
        "# Error of each stump\n",
        "grid_cv.best_estimator_.estimator_errors_"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bbd2e244",
      "metadata": {
        "id": "bbd2e244"
      },
      "source": [
        "\n",
        "**Stump Weightage** $=\\eta \\ln\\big(\\frac{1-\\text{Total Error}}{\\text{Total Error}}\\big)$\n",
        "\n",
        "For first stump, Total Error = 0.09457143\n",
        "\n",
        "$\\eta = 1.2$\n",
        "\n",
        "Stump Weightage = 2.7108635"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "286c5906",
      "metadata": {
        "id": "286c5906"
      },
      "outputs": [],
      "source": [
        "# Stump Weightage\n",
        "grid_cv.best_estimator_.estimator_weights_"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4bf1496",
      "metadata": {
        "id": "e4bf1496"
      },
      "source": [
        "**Making predictions on test set**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35fbef43",
      "metadata": {
        "id": "35fbef43"
      },
      "outputs": [],
      "source": [
        "# Predictions on test set\n",
        "y_pred = grid_cv.predict(test_X)\n",
        "\n",
        "# Generating Classification Report\n",
        "print(\"Classification Report - \\n\",\n",
        "      classification_report(test_y, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c246652",
      "metadata": {
        "id": "3c246652"
      },
      "source": [
        "**Generating Confusion Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18be5f27",
      "metadata": {
        "id": "18be5f27"
      },
      "outputs": [],
      "source": [
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(test_y, y_pred, labels = grid_cv.classes_)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = grid_cv.classes_)\n",
        "\n",
        "# Specify figure size and font size\n",
        "fig, ax = plt.subplots(figsize = (6, 6))\n",
        "plt.rcParams.update({'font.size': 15})\n",
        "\n",
        "# Display Confusion Matrix\n",
        "disp.plot(cmap = 'Purples', ax = ax);"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31a01f05",
      "metadata": {
        "id": "31a01f05"
      },
      "source": [
        "**Estimating Prediction Probabilites**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7928c22a",
      "metadata": {
        "id": "7928c22a"
      },
      "outputs": [],
      "source": [
        "# Getting prediction probabilites\n",
        "prob = grid_cv.predict_proba(test_X)\n",
        "\n",
        "# Printing prediction results\n",
        "result = pd.DataFrame({'Actual': test_y, 'Predicted': y_pred})\n",
        "\n",
        "# Creating columns for rejection and acceptance prob.\n",
        "result[['Prob. of 0','Prob. of 1']] = pd.DataFrame(prob.tolist(), index = result.index)\n",
        "\n",
        "# Saving dataframe as a csv file\n",
        "result.to_csv('Prediction Results.csv', index = False)\n",
        "\n",
        "result.sample(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5ffc41a",
      "metadata": {
        "id": "f5ffc41a"
      },
      "source": [
        "**Feature Importance**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4887c067",
      "metadata": {
        "id": "4887c067"
      },
      "outputs": [],
      "source": [
        "# Storing importance values from the best fit model\n",
        "importance = grid_cv.best_estimator_.feature_importances_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d73f7fad",
      "metadata": {
        "id": "d73f7fad"
      },
      "outputs": [],
      "source": [
        "# Displaying feature importance as a dataframe\n",
        "feature_imp = pd.DataFrame(list(zip(train_X.columns, importance)),\n",
        "               columns = ['Feature', 'Importance'])\n",
        "\n",
        "feature_imp = feature_imp.sort_values('Importance', ascending = False).reset_index(drop = True)\n",
        "\n",
        "feature_imp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d00a5c90",
      "metadata": {
        "id": "d00a5c90"
      },
      "outputs": [],
      "source": [
        "# Bar plot\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.barh(feature_imp['Feature'], feature_imp['Importance'], color =['teal','lime'])\n",
        "\n",
        "plt.xlabel(\"Importance\")\n",
        "plt.ylabel(\"Feature\")\n",
        "plt.title(\"Feature Importance\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P029DT-84aql"
      },
      "source": [
        "# **Prediction Intervals for Regression**\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1aBNgNCOASpQulzRzOwAmLvE4P1Eux0ZA\" width=\"500\" style=\"float: center\"/>\n",
        "\n",
        "### **What is a Prediction Interval?**\n",
        "- It is a **range of values** within which a new observation is expected to fall with a **certain probability**, given the existing data and model.\n",
        "\n",
        "- **Probability**: The width of the prediction interval depends on the **desired confidence level**, (e.g., 95%), with higher confidence levels leading to wider intervals.\n",
        "\n",
        "### **Confidence Level of Prediction Interval**\n",
        "\n",
        "- The confidence level of a prediction interval indicates the probability that the interval will contain the true value of the parameter being estimated.\n",
        "\n",
        "- Mathematically, the confidence level of a prediction interval is denoted by $ (1 - \\alpha) \\times 100\\% $, where $ \\alpha $ is the significance level.\n",
        "\n",
        "### **Why Prediction Intervals are Useful?**\n",
        "\n",
        "- **Uncertainty Quantification**: They provide a measure of the uncertainty in individual predictions, which is crucial for risk assessment and decision-making.\n",
        "\n",
        "- **Communication**: They are an effective tool for communicating the uncertainty in predictions to stakeholders, making the model's predictions more interpretable.\n",
        "\n",
        "\n"
      ],
      "id": "P029DT-84aql"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Case Study: Predicting the Price of Used Toyota Corolla Cars\n",
        "\n",
        "**In this case study, the objective is to predict the price of used Toyota Corolla Cars.**\n",
        "\n",
        "Data to be used: *ToyotaCorolla.csv*\n",
        "\n",
        "The data include the sales price and other information on the car, such as its age, mileage, fuel type, and engine size.\n",
        "\n",
        "Following is the description of columns in *ToyotaCorolla.csv* file\n",
        "\n",
        "<TABLE CAPTION=\"Car Sales Dataset\">\n",
        "<TR><TD><B>Variable</B></TD><TD><B>Description</B></TD></TR>\n",
        "<TR><TD>Price</TD><TD>Offer price in Euros</TD></TR>\n",
        "<TR><TD>Age</TD><TD>Age in months as of August 2004</TD></TR>\n",
        "<TR><TD>Kilometers</TD><TD>Accumulated kilometers on odometer</TD></TR>\n",
        "<TR><TD>Fuel type</TD><TD>Fuel type (Petrol, Diesel, CNG)</TD></TR>\n",
        "<TR><TD>HP</TD><TD>Horsepower</TD></TR>\n",
        "<TR><TD>Metallic</TD><TD>Metallic color? (Yes = 1, No = 0)</TD></TR>   \n",
        "<TR><TD>Automatic</TD><TD>Automatic? (Yes = 1, No = 0)</TD></TR>\n",
        "<TR><TD>CC</TD><TD>Cylinder volume in cubic centimeters</TD></TR>\n",
        "<TR><TD>Doors</TD><TD>Number of doors</TD></TR>\n",
        "<TR><TD>QuartTax</TD><TD>Quarterly road tax in Euros</TD></TR>\n",
        "<TR><TD>Weight</TD><TD>Weight in kilograms</TD></TR>\n",
        "</TABLE>"
      ],
      "metadata": {
        "id": "q5P-0zu3Z1qI"
      },
      "id": "q5P-0zu3Z1qI"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTwrq_0A4aqt"
      },
      "source": [
        "### Import Packages"
      ],
      "id": "dTwrq_0A4aqt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tcdzlYZu4aqt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd                  # Pandas\n",
        "import numpy as np                   # Numpy\n",
        "from matplotlib import pyplot as plt # Matplotlib\n",
        "\n",
        "# Package to implement Regression Tree Model\n",
        "import sklearn\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "# Package to implement Grid Search Cross Validation\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Package to visualize Decision Tree\n",
        "from sklearn import tree\n",
        "\n",
        "%matplotlib inline"
      ],
      "id": "tcdzlYZu4aqt"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g66C9pno4aqt"
      },
      "source": [
        "### Import and Prepare Data"
      ],
      "id": "g66C9pno4aqt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_q9pp9wW4aqt"
      },
      "outputs": [],
      "source": [
        "# Import Data\n",
        "car_df = pd.read_csv('ToyotaCorolla.csv')\n",
        "\n",
        "# Considering top 1000 rows for modeling and analysis\n",
        "car_df = car_df.iloc[0:1000]"
      ],
      "id": "_q9pp9wW4aqt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1f5a9ec"
      },
      "outputs": [],
      "source": [
        "# Selecting columns of interest\n",
        "predictors = ['Age_08_04', 'KM', 'Fuel_Type', 'HP', 'Met_Color', 'Automatic', 'CC',\n",
        "              'Doors', 'Quarterly_Tax', 'Weight']\n",
        "\n",
        "outcome = 'Price'"
      ],
      "id": "a1f5a9ec"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d170ee47"
      },
      "outputs": [],
      "source": [
        "# Creating dummy variables and specifiy the set of input and output variables\n",
        "X = pd.get_dummies(car_df[predictors], drop_first=True)\n",
        "y = car_df[outcome]"
      ],
      "id": "d170ee47"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VHRRNAh14aqu"
      },
      "outputs": [],
      "source": [
        "# Data Partitioning into train and test sets\n",
        "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.3, random_state=1)"
      ],
      "id": "VHRRNAh14aqu"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ka3ZglSb4aqu"
      },
      "source": [
        "### Hyperparameter Tuning using Grid Search Cross Validation"
      ],
      "id": "ka3ZglSb4aqu"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgC85a4g4aqu"
      },
      "outputs": [],
      "source": [
        "# Define your model\n",
        "reg = DecisionTreeRegressor(random_state = 42)"
      ],
      "id": "zgC85a4g4aqu"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_z_g3244aqu"
      },
      "outputs": [],
      "source": [
        "# Start with an initial guess for parameters\n",
        "hyper_params = {\n",
        "    'max_depth': [5, 10, 15, 20],\n",
        "    'min_samples_split': [20, 40, 60],\n",
        "    'min_samples_leaf': [10, 20, 30, 40, 50]\n",
        "}"
      ],
      "id": "J_z_g3244aqu"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mvSOpZBS4aqu"
      },
      "outputs": [],
      "source": [
        "# Creating folds\n",
        "folds = KFold(n_splits = 5, shuffle = True, random_state = 100)"
      ],
      "id": "mvSOpZBS4aqu"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WVRLKN9U4aqv"
      },
      "outputs": [],
      "source": [
        "# Call GridSearchCV()\n",
        "model_cv = GridSearchCV(estimator = reg,\n",
        "                        param_grid = hyper_params,\n",
        "                        scoring = 'r2', # Use a suitable regression metric\n",
        "                        cv = folds,\n",
        "                        verbose = 1,\n",
        "                        n_jobs = -1) # Will utilize all available CPUs"
      ],
      "id": "WVRLKN9U4aqv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crBXw8Ep4aqv"
      },
      "outputs": [],
      "source": [
        "# Fit the model\n",
        "model_cv.fit(train_X, train_y)"
      ],
      "id": "crBXw8Ep4aqv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VM_IF3F04aqv"
      },
      "outputs": [],
      "source": [
        "print('Initial score: ', model_cv.best_score_)\n",
        "print('Initial parameters: ', model_cv.best_params_)"
      ],
      "id": "VM_IF3F04aqv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87914416"
      },
      "outputs": [],
      "source": [
        "# Adapt grid based on result from initial grid search\n",
        "hyper_params_new = {\n",
        "    'max_depth': list(range(2, 12)),\n",
        "    'min_samples_split': list(range(15, 24)),\n",
        "    'min_samples_leaf': list(range(2, 10))\n",
        "}"
      ],
      "id": "87914416"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "veafY-_74aqv"
      },
      "outputs": [],
      "source": [
        "# Call GridSearchCV()\n",
        "model_cv = GridSearchCV(estimator = reg,\n",
        "                        param_grid = hyper_params_new,\n",
        "                        scoring = 'r2',\n",
        "                        cv = folds,\n",
        "                        verbose = 1,\n",
        "                        n_jobs = -1) # Will utilize all available CPUs"
      ],
      "id": "veafY-_74aqv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3Yk5Aq54aqv"
      },
      "outputs": [],
      "source": [
        "# Fit the model\n",
        "model_cv.fit(train_X, train_y)"
      ],
      "id": "_3Yk5Aq54aqv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BgXJ0Bi34aqw"
      },
      "outputs": [],
      "source": [
        "print('Improved score: ', model_cv.best_score_)\n",
        "print('Improved parameters: ', model_cv.best_params_)"
      ],
      "id": "BgXJ0Bi34aqw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWgl7Sh94aqw"
      },
      "outputs": [],
      "source": [
        "# Storing best model\n",
        "bestRegTree = model_cv.best_estimator_\n",
        "\n",
        "# Visualizing Decision Tree\n",
        "fig = plt.figure(figsize=(25,20))\n",
        "a = tree.plot_tree(decision_tree = bestRegTree,\n",
        "                   feature_names = train_X.columns,\n",
        "                   filled = True)"
      ],
      "id": "HWgl7Sh94aqw"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f74fec70"
      },
      "source": [
        "### Evaluating Performance of Tuned Model on Test Set"
      ],
      "id": "f74fec70"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2696eccf"
      },
      "outputs": [],
      "source": [
        "# Predict test set\n",
        "y_pred = model_cv.predict(test_X)\n",
        "r2 = sklearn.metrics.r2_score(test_y, y_pred)\n",
        "RMSE = sklearn.metrics.root_mean_squared_error(test_y, y_pred)\n",
        "print(r2,RMSE)"
      ],
      "id": "2696eccf"
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "id": "_Q6niPx97ZFj"
      },
      "id": "_Q6niPx97ZFj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Prediction Intervals using MAPIE Regressor**\n",
        "\n",
        "#### ***MAPIE: Model Agnostic Prediction Interval Estimator***\n",
        "- It is a Python library designed to estimate prediction intervals in a **model-agnostic way**.\n",
        "- It can be used with **any machine learning model**, including linear models, decision trees, ensemble methods, and neural networks.\n",
        "\n",
        "[**See this link for detailed description on `MAPIE`**](https://mapie.readthedocs.io/en/latest/generated/mapie.regression.MapieRegressor.html)"
      ],
      "metadata": {
        "id": "jRlnI79yFoFq"
      },
      "id": "jRlnI79yFoFq"
    },
    {
      "cell_type": "code",
      "source": [
        "# Best Regression Model/Tree after hyperparameter tuning\n",
        "bestRegTree"
      ],
      "metadata": {
        "id": "iMt5yMCmFnIN"
      },
      "execution_count": null,
      "outputs": [],
      "id": "iMt5yMCmFnIN"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Install and Import `MAPIE` Library**"
      ],
      "metadata": {
        "id": "AYOuh6fChkOs"
      },
      "id": "AYOuh6fChkOs"
    },
    {
      "cell_type": "code",
      "source": [
        "# Install mapie\n",
        "!pip install -q mapie"
      ],
      "metadata": {
        "id": "kSSvTEXUhc9n"
      },
      "id": "kSSvTEXUhc9n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import mapie\n",
        "from mapie.regression import MapieRegressor"
      ],
      "metadata": {
        "id": "cvvXZVrshgdP"
      },
      "id": "cvvXZVrshgdP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define mapie regressor\n",
        "mapie = MapieRegressor(estimator = bestRegTree, # Prediction model to use\n",
        "                       n_jobs = -1,\n",
        "                       random_state = 42)\n",
        "\n",
        "# Fit mapie regressor on training data\n",
        "mapie.fit(train_X, train_y)\n",
        "\n",
        "alpha = 0.1 # For 90% confidence level\n",
        "\n",
        "# Use mapie.predict() to get predicted values and intervals\n",
        "y_test_pred, y_test_pis = mapie.predict(test_X, alpha = alpha)"
      ],
      "metadata": {
        "id": "b3D-u5giFk1F"
      },
      "execution_count": null,
      "outputs": [],
      "id": "b3D-u5giFk1F"
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicted values\n",
        "y_test_pred"
      ],
      "metadata": {
        "id": "eQXceYh-6_A9",
        "collapsed": true
      },
      "id": "eQXceYh-6_A9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction Intervals\n",
        "y_test_pis"
      ],
      "metadata": {
        "id": "yoy6nber7HhU",
        "collapsed": true
      },
      "id": "yoy6nber7HhU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Storing results in a dataframe\n",
        "predictions = test_y.to_frame()\n",
        "predictions.columns = ['Actual Value']\n",
        "predictions[\"Predicted Value\"] = y_test_pred.round()\n",
        "predictions[\"Lower Value\"] = y_test_pis[:, 0].round()\n",
        "predictions[\"Upper Value\"] = y_test_pis[:, 1].round()\n",
        "\n",
        "# Take a quick look\n",
        "predictions"
      ],
      "metadata": {
        "id": "PNYdJnjIJgzU"
      },
      "execution_count": null,
      "outputs": [],
      "id": "PNYdJnjIJgzU"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Coverage Calculation**\n",
        "- **Coverage** refers to the proportion of true/actual values that fall within the prediction intervals generated by a model.\n",
        "\n",
        "- It is a measure of how well the prediction intervals capture the actual values.\n",
        "\n",
        "  $\\text{Coverage} = \\frac{\\text{Number of actual values within prediction intervals}}{\\text{Total number of actual values}}$\n"
      ],
      "metadata": {
        "id": "pX-USgiDlNWk"
      },
      "id": "pX-USgiDlNWk"
    },
    {
      "cell_type": "code",
      "source": [
        "# To calculate coverage score\n",
        "from mapie.metrics import regression_coverage_score"
      ],
      "metadata": {
        "id": "-CyWYmXIl8ip"
      },
      "id": "-CyWYmXIl8ip",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coverage = regression_coverage_score(test_y,           # Actual values\n",
        "                                     y_test_pis[:, 0], # Lower bound of prediction intervals\n",
        "                                     y_test_pis[:, 1]) # Upper bound of prediction intervals\n",
        "\n",
        "coverage_percentage = coverage * 100\n",
        "print(f\"Coverage: {coverage_percentage:.2f}%\")"
      ],
      "metadata": {
        "id": "EW_yusBwigPi"
      },
      "id": "EW_yusBwigPi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Coverage Plot (sorted by prediction interval width)**"
      ],
      "metadata": {
        "id": "KZ4F5fMiPGA-"
      },
      "id": "KZ4F5fMiPGA-"
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary library for setting up the plot format\n",
        "import matplotlib as mpl\n",
        "\n",
        "# Sort the predictions by 'Actual Value' for better visualization and reset the index\n",
        "sorted_predictions = predictions.sort_values(by=['Actual Value']).reset_index(drop=True)\n",
        "\n",
        "# Create a figure and axis object with specified size and resolution\n",
        "fig, ax = plt.subplots(figsize=(25, 10), dpi=250)\n",
        "\n",
        "# Plot the actual values with green dots\n",
        "plt.plot(sorted_predictions[\"Actual Value\"], 'go', markersize=4, label=\"Actual Value\")\n",
        "\n",
        "# Fill the area between the lower and upper bounds of the prediction intervals with semi-transparent green color\n",
        "plt.fill_between(np.arange(len(sorted_predictions)),\n",
        "                 sorted_predictions[\"Lower Value\"],\n",
        "                 sorted_predictions[\"Upper Value\"],\n",
        "                 alpha=0.2, color=\"green\", label=\"Prediction Interval\")\n",
        "\n",
        "# Set font size for x and y ticks\n",
        "plt.xticks(fontsize=15)\n",
        "plt.yticks(fontsize=15)\n",
        "\n",
        "# Format y-axis to show values with commas as thousand separators\n",
        "ax.yaxis.set_major_formatter(mpl.ticker.StrMethodFormatter('{x:,.0f}'))\n",
        "\n",
        "# Set the limit for the x-axis to cover the range of samples\n",
        "plt.xlim([0, len(sorted_predictions)])\n",
        "\n",
        "# Label the x-axis and y-axis with appropriate font size\n",
        "plt.xlabel(\"Samples\", fontsize=20)\n",
        "plt.ylabel(\"Target\", fontsize=20)\n",
        "\n",
        "# Add a title to the plot, including the coverage percentage, with bold formatting\n",
        "plt.title(f\"Prediction Intervals and Coverage: {coverage_percentage:.2f}%\", fontsize=25, fontweight=\"bold\")\n",
        "\n",
        "# Add a legend to the plot, placed in the upper left, with specified font size\n",
        "plt.legend(loc=\"upper left\", fontsize=20)\n",
        "\n",
        "# Save the plot as a PDF file with tight layout\n",
        "plt.savefig(\"prediction_intervals_coverage.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
        "\n",
        "# Display the plot\n",
        "plt.show();\n"
      ],
      "metadata": {
        "id": "su1BcD2hrNao"
      },
      "id": "su1BcD2hrNao",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "a2d85c8b",
        "08e3da84",
        "4bd693da",
        "4ed9b74c",
        "42072cec",
        "870be840",
        "04057072",
        "fe21bd60",
        "P029DT-84aql",
        "q5P-0zu3Z1qI",
        "dTwrq_0A4aqt",
        "g66C9pno4aqt",
        "ka3ZglSb4aqu",
        "f74fec70",
        "jRlnI79yFoFq",
        "pX-USgiDlNWk"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}